'use client';

import React, { useEffect, useRef, useState, useCallback } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { useCrewAI } from '@/hooks/useCrewAI';
import { toast } from 'react-hot-toast';
import { ChatInterface } from './ChatInterface';
import { io, Socket } from 'socket.io-client';
import { 
  Mic, 
  MicOff, 
  MessageCircle, 
  X, 
  Volume2, 
  VolumeX,
  Loader2,
  Phone,
  FileText,
  Calendar,
  Globe
} from 'lucide-react';

declare global {
  interface Window {
    webkitSpeechRecognition: typeof SpeechRecognition;
    webkitAudioContext: typeof AudioContext;
  }
  interface SpeechRecognitionEvent extends Event {
    resultIndex: number;
    results: SpeechRecognitionResultList;
  }
}

interface VirtualAssistantProps {
  onMessage?: (message: string) => void;
  language: 'en' | 'es';
  userId?: string;
}

interface ConversationState {
  isListening: boolean;
  isSpeaking: boolean;
  isProcessing: boolean;
  transcript: string;
  interimTranscript: string;
  error: string | null;
}

export const VirtualAssistant: React.FC<VirtualAssistantProps> = ({
  onMessage,
  language,
  userId = 'anonymous',
}) => {
  // State management
  const [isOpen, setIsOpen] = useState(false);
  const [mode, setMode] = useState<'chat' | 'voice' | 'consultation' | 'appointment' | 'document'>('chat');
  const [conversationState, setConversationState] = useState<ConversationState>({
    isListening: false,
    isSpeaking: false,
    isProcessing: false,
    transcript: '',
    interimTranscript: '',
    error: null,
  });
  const [isVoiceEnabled, setIsVoiceEnabled] = useState(true);
  const [socket, setSocket] = useState<Socket | null>(null);
  const [isConnected, setIsConnected] = useState(false);
  const [consultationData, setConsultationData] = useState({
    caseType: '',
    description: '',
    urgency: 'medium' as 'low' | 'medium' | 'high',
  });

  // Refs
  const recognitionRef = useRef<any>(null);
  const synthRef = useRef<SpeechSynthesisUtterance | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const animationFrameRef = useRef<number | null>(null);

  const {
    isLoading,
    activeTasks,
    createLegalConsultationTask,
    createAppointmentSchedulingTask,
    createDocumentAnalysisTask,
    createClientIntakeWorkflow,
    getTaskStatus,
  } = useCrewAI();

  // Initialize WebSocket connection
  useEffect(() => {
    if (isOpen && !socket) {
      const socketUrl = process.env.NEXT_PUBLIC_WEBSOCKET_URL || 
        (typeof window !== 'undefined' ? `${window.location.protocol}//${window.location.host}` : 'http://localhost:3000');
      
      const newSocket = io(socketUrl, {
        transports: ['websocket', 'polling'],
        auth: {
          sessionId: `session_${Date.now()}`,
          language,
          userId,
        },
        reconnection: true,
        reconnectionAttempts: 5,
        reconnectionDelay: 1000,
      });

      newSocket.on('connect', () => {
        setIsConnected(true);
        newSocket.emit('chat:init', { userId, language });
      });

      newSocket.on('disconnect', () => {
        setIsConnected(false);
      });

      newSocket.on('assistant:message', (data: { text: string; metadata?: any }) => {
        if (mode === 'voice' && isVoiceEnabled) {
          speakText(data.text);
        }
      });

      newSocket.on('error', (error: { message: string }) => {
        toast.error(error.message);
        setConversationState(prev => ({ ...prev, error: error.message }));
      });

      setSocket(newSocket);
    }

    return () => {
      if (socket) {
        socket.disconnect();
        setSocket(null);
      }
    };
  }, [isOpen, language, userId, mode, isVoiceEnabled]);

  // Voice message handler (moved before speech recognition for dependency)
  const handleVoiceMessage = useCallback((transcript: string) => {
    if (!transcript.trim() || !socket) return;

    setConversationState(prev => ({ 
      ...prev, 
      isProcessing: true, 
      transcript: '',
      interimTranscript: '' 
    }));

    // Send via WebSocket
    socket.emit('user:message', {
      text: transcript,
      language,
      timestamp: new Date().toISOString(),
    });

    // Stop listening while processing
    if (recognitionRef.current && conversationState.isListening) {
      recognitionRef.current.stop();
    }

    onMessage?.(transcript);

    setTimeout(() => {
      setConversationState(prev => ({ ...prev, isProcessing: false }));
    }, 500);
  }, [socket, language, onMessage, conversationState.isListening]);

  // Initialize speech recognition
  useEffect(() => {
    if (typeof window !== 'undefined' && 'webkitSpeechRecognition' in window) {
      const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
      const recognition = new SpeechRecognition();

      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = language === 'es' ? 'es-ES' : 'en-US';
      recognition.maxAlternatives = 1;

      recognition.onstart = () => {
        setConversationState(prev => ({ 
          ...prev, 
          isListening: true, 
          error: null,
          transcript: '',
          interimTranscript: '' 
        }));
      };

      recognition.onresult = (event: SpeechRecognitionEvent) => {
        let interimTranscript = '';
        let finalTranscript = '';

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript + ' ';
          } else {
            interimTranscript += transcript;
          }
        }

        setConversationState(prev => ({
          ...prev,
          interimTranscript,
          transcript: prev.transcript + finalTranscript,
        }));

        // Auto-send on sentence completion
        if (finalTranscript.trim() && 
            (finalTranscript.includes('.') || 
             finalTranscript.includes('?') || 
             finalTranscript.includes('!'))) {
          const currentTranscript = conversationState.transcript + finalTranscript;
          handleVoiceMessage(currentTranscript);
        }
      };

      recognition.onerror = (event: any) => {
        console.error('Speech recognition error:', event.error);
        setConversationState(prev => ({ 
          ...prev, 
          isListening: false, 
          error: getErrorMessage(event.error, language) 
        }));
      };

      recognition.onend = () => {
        setConversationState(prev => ({ ...prev, isListening: false }));
      };

      recognitionRef.current = recognition;
    }

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, [language, conversationState.transcript, handleVoiceMessage]);

  // Initialize audio context for voice visualization
  useEffect(() => {
    if (typeof window !== 'undefined' && !audioContextRef.current) {
      const AudioContext = window.AudioContext || window.webkitAudioContext;
      audioContextRef.current = new AudioContext();
    }
  }, []);

  // Voice control functions
  const toggleListening = useCallback(() => {
    if (!recognitionRef.current) {
      toast.error(language === 'es' 
        ? 'Tu navegador no soporta reconocimiento de voz' 
        : 'Your browser does not support speech recognition'
      );
      return;
    }

    if (conversationState.isListening) {
      recognitionRef.current.stop();
    } else {
      // Stop any ongoing speech
      if (window.speechSynthesis.speaking) {
        window.speechSynthesis.cancel();
      }
      recognitionRef.current.start();
    }
  }, [conversationState.isListening, language]);

  const speakText = useCallback((text: string) => {
    if (!isVoiceEnabled || !window.speechSynthesis) return;

    // Cancel any ongoing speech
    window.speechSynthesis.cancel();

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = language === 'es' ? 'es-ES' : 'en-US';
    utterance.rate = 0.9;
    utterance.pitch = 1;
    utterance.volume = 1;

    utterance.onstart = () => {
      setConversationState(prev => ({ ...prev, isSpeaking: true }));
    };

    utterance.onend = () => {
      setConversationState(prev => ({ ...prev, isSpeaking: false }));
      // Resume listening if it was active
      if (mode === 'voice' && conversationState.isListening) {
        setTimeout(() => {
          recognitionRef.current?.start();
        }, 500);
      }
    };

    utterance.onerror = (event) => {
      console.error('Speech synthesis error:', event);
      setConversationState(prev => ({ ...prev, isSpeaking: false }));
    };

    synthRef.current = utterance;
    window.speechSynthesis.speak(utterance);
  }, [isVoiceEnabled, language, mode, conversationState.isListening]);

  // Consultation submission
  const handleConsultationSubmit = async () => {
    if (!consultationData.caseType || !consultationData.description) {
      toast.error(language === 'es' 
        ? 'Por favor completa todos los campos requeridos' 
        : 'Please fill in all required fields'
      );
      return;
    }

    try {
      await createClientIntakeWorkflow({
        userId,
        caseType: consultationData.caseType,
        description: consultationData.description,
        urgency: consultationData.urgency,
        language,
      });

      toast.success(language === 'es' 
        ? 'Consulta iniciada exitosamente' 
        : 'Consultation started successfully'
      );
      setMode('voice');
      setConsultationData({ caseType: '', description: '', urgency: 'medium' });
    } catch (error) {
      console.error('Failed to start consultation:', error);
      toast.error(language === 'es' 
        ? 'Error al iniciar la consulta' 
        : 'Failed to start consultation'
      );
    }
  };

  // Document upload
  const handleFileUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;

    try {
      await createDocumentAnalysisTask(file, {
        userId,
        documentType: 'other',
        analysisType: 'full-analysis',
        language,
        urgency: 'medium',
      });

      toast.success(language === 'es' 
        ? 'Documento cargado exitosamente' 
        : 'Document uploaded successfully'
      );
      setMode('voice');
    } catch (error) {
      console.error('Failed to start document analysis:', error);
      toast.error(language === 'es' 
        ? 'Error al cargar el documento' 
        : 'Failed to upload document'
      );
    }
  };

  // Clean up on unmount
  useEffect(() => {
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      if (window.speechSynthesis.speaking) {
        window.speechSynthesis.cancel();
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, []);

  return (
    <>
      {/* Floating Assistant Button */}
      <motion.button
        className="fixed bottom-24 right-8 w-16 h-16 bg-gradient-to-r from-burgundy-600 to-burgundy-700 text-white rounded-full shadow-lg hover:shadow-xl transition-all z-40 flex items-center justify-center group"
        whileHover={{ scale: 1.05 }}
        whileTap={{ scale: 0.95 }}
        onClick={() => setIsOpen(!isOpen)}
        aria-label={language === 'es' ? 'Abrir asistente virtual' : 'Open virtual assistant'}
      >
        <AnimatePresence mode="wait">
          {isOpen ? (
            <motion.div
              key="close"
              initial={{ rotate: -90, opacity: 0 }}
              animate={{ rotate: 0, opacity: 1 }}
              exit={{ rotate: 90, opacity: 0 }}
              transition={{ duration: 0.2 }}
            >
              <X className="w-8 h-8" />
            </motion.div>
          ) : (
            <motion.div
              key="open"
              initial={{ rotate: 90, opacity: 0 }}
              animate={{ rotate: 0, opacity: 1 }}
              exit={{ rotate: -90, opacity: 0 }}
              transition={{ duration: 0.2 }}
            >
              <MessageCircle className="w-8 h-8" />
            </motion.div>
          )}
        </AnimatePresence>
        
        {/* Pulse animation when closed */}
        {!isOpen && (
          <motion.div
            className="absolute inset-0 bg-burgundy-600 rounded-full"
            animate={{
              scale: [1, 1.3, 1],
              opacity: [0.5, 0, 0.5],
            }}
            transition={{
              duration: 2,
              repeat: Infinity,
              ease: "easeInOut",
            }}
          />
        )}
      </motion.button>

      {/* Assistant Interface */}
      <AnimatePresence>
        {isOpen && (
          <motion.div
            initial={{ opacity: 0, y: 20, scale: 0.9 }}
            animate={{ opacity: 1, y: 0, scale: 1 }}
            exit={{ opacity: 0, y: 20, scale: 0.9 }}
            transition={{ type: "spring", damping: 25, stiffness: 300 }}
            className="fixed bottom-44 right-8 w-96 bg-white dark:bg-gray-900 rounded-2xl shadow-2xl z-50 overflow-hidden"
          >
            {/* Header */}
            <div className="bg-gradient-to-r from-burgundy-600 to-burgundy-700 text-white p-4">
              <div className="flex items-center justify-between mb-2">
                <h3 className="text-lg font-semibold">
                  {language === 'es' ? 'Asistente Legal Virtual' : 'Virtual Legal Assistant'}
                </h3>
                <button
                  onClick={() => setIsOpen(false)}
                  className="text-white/80 hover:text-white transition-colors"
                  aria-label={language === 'es' ? 'Cerrar' : 'Close'}
                >
                  <X className="w-5 h-5" />
                </button>
              </div>
              
              {/* Mode tabs */}
              <div className="flex gap-1">
                {[
                  { id: 'chat', icon: MessageCircle, label: language === 'es' ? 'Chat' : 'Chat' },
                  { id: 'voice', icon: Mic, label: language === 'es' ? 'Voz' : 'Voice' },
                  { id: 'consultation', icon: FileText, label: language === 'es' ? 'Consulta' : 'Consult' },
                  { id: 'appointment', icon: Calendar, label: language === 'es' ? 'Cita' : 'Appt' },
                  { id: 'document', icon: FileText, label: language === 'es' ? 'Doc' : 'Doc' },
                ].map(({ id, icon: Icon, label }) => (
                  <button
                    key={id}
                    onClick={() => setMode(id as any)}
                    className={`flex-1 px-2 py-1.5 rounded text-xs font-medium transition-colors flex items-center justify-center gap-1 ${
                      mode === id 
                        ? 'bg-white text-burgundy-600' 
                        : 'bg-burgundy-500/20 hover:bg-burgundy-500/30'
                    }`}
                  >
                    <Icon className="w-3 h-3" />
                    <span className="hidden sm:inline">{label}</span>
                  </button>
                ))}
              </div>
            </div>

            {/* Connection status */}
            {mode !== 'chat' && (
              <div className="px-4 py-2 bg-gray-50 dark:bg-gray-800 border-b dark:border-gray-700">
                <div className="flex items-center justify-between text-xs">
                  <div className="flex items-center gap-2">
                    <div className={`w-2 h-2 rounded-full ${isConnected ? 'bg-green-500' : 'bg-red-500'}`} />
                    <span className="text-gray-600 dark:text-gray-400">
                      {isConnected 
                        ? (language === 'es' ? 'Conectado' : 'Connected')
                        : (language === 'es' ? 'Desconectado' : 'Disconnected')
                      }
                    </span>
                  </div>
                  {mode === 'voice' && (
                    <button
                      onClick={() => setIsVoiceEnabled(!isVoiceEnabled)}
                      className="text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100"
                    >
                      {isVoiceEnabled ? <Volume2 className="w-4 h-4" /> : <VolumeX className="w-4 h-4" />}
                    </button>
                  )}
                </div>
              </div>
            )}

            {/* Content area */}
            <div className="h-[400px] overflow-hidden">
              {/* Loading overlay */}
              {isLoading && (
                <div className="absolute inset-0 bg-white/80 dark:bg-gray-900/80 flex items-center justify-center z-10">
                  <div className="text-center">
                    <Loader2 className="w-8 h-8 animate-spin text-burgundy-600 mx-auto mb-2" />
                    <p className="text-sm text-gray-600 dark:text-gray-400">
                      {language === 'es' ? 'Procesando...' : 'Processing...'}
                    </p>
                  </div>
                </div>
              )}

              {/* Active tasks indicator */}
              {activeTasks.length > 0 && (
                <div className="px-4 py-2 bg-amber-50 dark:bg-amber-900/20 border-b border-amber-200 dark:border-amber-800">
                  <p className="text-xs text-amber-800 dark:text-amber-200">
                    {language === 'es' 
                      ? `${activeTasks.length} tarea(s) activa(s)` 
                      : `${activeTasks.length} active task(s)`
                    }
                  </p>
                </div>
              )}

              {/* Mode-specific content */}
              {mode === 'chat' && (
                <ChatInterface
                  language={language}
                  userId={userId}
                  onScheduleAppointment={() => setMode('appointment')}
                  onCallRequest={() => window.location.href = 'tel:18449673536'}
                />
              )}

              {mode === 'voice' && (
                <div className="h-full flex flex-col items-center justify-center p-6">
                  {/* Voice visualization */}
                  <div className="relative mb-8">
                    <motion.div
                      className="w-32 h-32 rounded-full bg-gradient-to-br from-burgundy-500 to-burgundy-700 flex items-center justify-center"
                      animate={conversationState.isListening ? {
                        scale: [1, 1.1, 1],
                      } : {}}
                      transition={{
                        duration: 1.5,
                        repeat: conversationState.isListening ? Infinity : 0,
                        ease: "easeInOut",
                      }}
                    >
                      {conversationState.isSpeaking ? (
                        <Volume2 className="w-12 h-12 text-white" />
                      ) : conversationState.isListening ? (
                        <Mic className="w-12 h-12 text-white" />
                      ) : (
                        <MicOff className="w-12 h-12 text-white/60" />
                      )}
                    </motion.div>

                    {/* Speaking animation */}
                    {conversationState.isSpeaking && (
                      <div className="absolute inset-0 flex items-center justify-center">
                        <div className="flex gap-1">
                          {[0, 1, 2, 3].map(i => (
                            <motion.div
                              key={i}
                              className="w-1 h-8 bg-burgundy-600 rounded-full"
                              animate={{
                                scaleY: [0.3, 1, 0.3],
                              }}
                              transition={{
                                duration: 0.6,
                                repeat: Infinity,
                                delay: i * 0.15,
                              }}
                            />
                          ))}
                        </div>
                      </div>
                    )}
                  </div>

                  {/* Transcript display */}
                  {(conversationState.transcript || conversationState.interimTranscript) && (
                    <motion.div
                      initial={{ opacity: 0, y: 10 }}
                      animate={{ opacity: 1, y: 0 }}
                      className="w-full mb-4 p-3 bg-gray-100 dark:bg-gray-800 rounded-lg"
                    >
                      <p className="text-sm text-gray-900 dark:text-gray-100">
                        {conversationState.transcript}
                        <span className="text-gray-500 dark:text-gray-400">
                          {conversationState.interimTranscript}
                        </span>
                      </p>
                    </motion.div>
                  )}

                  {/* Error display */}
                  {conversationState.error && (
                    <motion.div
                      initial={{ opacity: 0 }}
                      animate={{ opacity: 1 }}
                      className="w-full mb-4 p-3 bg-red-50 dark:bg-red-900/20 border border-red-200 dark:border-red-800 rounded-lg"
                    >
                      <p className="text-sm text-red-600 dark:text-red-400">
                        {conversationState.error}
                      </p>
                    </motion.div>
                  )}

                  {/* Voice control button */}
                  <motion.button
                    className={`w-20 h-20 rounded-full shadow-lg transition-all ${
                      conversationState.isListening 
                        ? 'bg-red-500 hover:bg-red-600' 
                        : 'bg-burgundy-600 hover:bg-burgundy-700'
                    } text-white`}
                    whileHover={{ scale: 1.05 }}
                    whileTap={{ scale: 0.95 }}
                    onClick={toggleListening}
                    disabled={conversationState.isProcessing}
                  >
                    {conversationState.isProcessing ? (
                      <Loader2 className="w-8 h-8 mx-auto animate-spin" />
                    ) : conversationState.isListening ? (
                      <MicOff className="w-8 h-8 mx-auto" />
                    ) : (
                      <Mic className="w-8 h-8 mx-auto" />
                    )}
                  </motion.button>

                  <p className="mt-4 text-sm text-gray-600 dark:text-gray-400 text-center">
                    {conversationState.isProcessing
                      ? language === 'es' ? 'Procesando...' : 'Processing...'
                      : conversationState.isListening
                        ? language === 'es' ? 'Escuchando... Haz clic para detener' : 'Listening... Click to stop'
                        : language === 'es' ? 'Haz clic para hablar' : 'Click to speak'
                    }
                  </p>

                  {/* Quick actions */}
                  <div className="mt-6 flex gap-2">
                    <button
                      onClick={() => window.location.href = 'tel:18449673536'}
                      className="text-xs text-gray-600 dark:text-gray-400 hover:text-burgundy-600 dark:hover:text-burgundy-400 flex items-center gap-1"
                    >
                      <Phone className="w-3 h-3" />
                      {language === 'es' ? 'Llamar' : 'Call'}
                    </button>
                    <button
                      onClick={() => setMode('chat')}
                      className="text-xs text-gray-600 dark:text-gray-400 hover:text-burgundy-600 dark:hover:text-burgundy-400 flex items-center gap-1"
                    >
                      <MessageCircle className="w-3 h-3" />
                      {language === 'es' ? 'Chat' : 'Chat'}
                    </button>
                  </div>
                </div>
              )}

              {/* Consultation form */}
              {mode === 'consultation' && (
                <div className="p-6 space-y-4">
                  <select
                    value={consultationData.caseType}
                    onChange={e => setConsultationData(prev => ({ ...prev, caseType: e.target.value }))}
                    className="w-full px-3 py-2 border border-gray-300 dark:border-gray-600 rounded-lg bg-white dark:bg-gray-800 text-gray-900 dark:text-gray-100 focus:ring-2 focus:ring-burgundy-500 focus:border-transparent"
                  >
                    <option value="">
                      {language === 'es' ? 'Seleccionar tipo de caso' : 'Select case type'}
                    </option>
                    <option value="immigration">
                      {language === 'es' ? 'Inmigración' : 'Immigration'}
                    </option>
                    <option value="personal-injury">
                      {language === 'es' ? 'Lesiones Personales' : 'Personal Injury'}
                    </option>
                    <option value="workers-comp">
                      {language === 'es' ? 'Compensación Laboral' : 'Workers Compensation'}
                    </option>
                    <option value="criminal-defense">
                      {language === 'es' ? 'Defensa Criminal' : 'Criminal Defense'}
                    </option>
                    <option value="family-law">
                      {language === 'es' ? 'Derecho Familiar' : 'Family Law'}
                    </option>
                  </select>

                  <textarea
                    value={consultationData.description}
                    onChange={e => setConsultationData(prev => ({ ...prev, description: e.target.value }))}
                    placeholder={
                      language === 'es'
                        ? 'Describe brevemente tu situación legal...'
                        : 'Briefly describe your legal situation...'
                    }
                    className="w-full px-3 py-2 border border-gray-300 dark:border-gray-600 rounded-lg bg-white dark:bg-gray-800 text-gray-900 dark:text-gray-100 focus:ring-2 focus:ring-burgundy-500 focus:border-transparent h-32 resize-none"
                  />

                  <select
                    value={consultationData.urgency}
                    onChange={e => setConsultationData(prev => ({ ...prev, urgency: e.target.value as any }))}
                    className="w-full px-3 py-2 border border-gray-300 dark:border-gray-600 rounded-lg bg-white dark:bg-gray-800 text-gray-900 dark:text-gray-100 focus:ring-2 focus:ring-burgundy-500 focus:border-transparent"
                  >
                    <option value="low">
                      {language === 'es' ? 'Baja urgencia' : 'Low urgency'}
                    </option>
                    <option value="medium">
                      {language === 'es' ? 'Urgencia media' : 'Medium urgency'}
                    </option>
                    <option value="high">
                      {language === 'es' ? 'Alta urgencia' : 'High urgency'}
                    </option>
                  </select>

                  <button
                    onClick={handleConsultationSubmit}
                    disabled={isLoading || !consultationData.caseType || !consultationData.description}
                    className="w-full py-3 bg-burgundy-600 text-white rounded-lg hover:bg-burgundy-700 disabled:opacity-50 disabled:cursor-not-allowed transition-colors font-medium"
                  >
                    {language === 'es' ? 'Iniciar Consulta' : 'Start Consultation'}
                  </button>
                </div>
              )}

              {/* Document upload */}
              {mode === 'document' && (
                <div className="p-6">
                  <input
                    type="file"
                    accept=".pdf,.txt,.doc,.docx,.jpg,.jpeg,.png"
                    onChange={handleFileUpload}
                    className="hidden"
                    id="document-upload"
                  />
                  <label
                    htmlFor="document-upload"
                    className="block w-full p-12 border-2 border-dashed border-gray-300 dark:border-gray-600 rounded-lg cursor-pointer hover:border-burgundy-500 dark:hover:border-burgundy-400 transition-colors"
                  >
                    <div className="text-center">
                      <FileText className="w-12 h-12 mx-auto mb-4 text-gray-400" />
                      <p className="text-sm text-gray-600 dark:text-gray-400 mb-2">
                        {language === 'es'
                          ? 'Haz clic o arrastra un documento aquí'
                          : 'Click or drag a document here'}
                      </p>
                      <p className="text-xs text-gray-500 dark:text-gray-500">
                        PDF, Word, TXT, Images (max 10MB)
                      </p>
                    </div>
                  </label>
                </div>
              )}

              {/* Appointment scheduling */}
              {mode === 'appointment' && (
                <div className="p-6 text-center">
                  <Calendar className="w-16 h-16 mx-auto mb-4 text-gray-400" />
                  <h4 className="text-lg font-medium text-gray-900 dark:text-gray-100 mb-2">
                    {language === 'es' ? 'Programar una Cita' : 'Schedule an Appointment'}
                  </h4>
                  <p className="text-sm text-gray-600 dark:text-gray-400 mb-6">
                    {language === 'es'
                      ? 'Nuestro equipo está listo para ayudarte. Llámanos para programar tu consulta gratuita.'
                      : 'Our team is ready to help you. Call us to schedule your free consultation.'}
                  </p>
                  <a
                    href="tel:18449673536"
                    className="inline-flex items-center gap-2 px-6 py-3 bg-burgundy-600 text-white rounded-lg hover:bg-burgundy-700 transition-colors font-medium"
                  >
                    <Phone className="w-5 h-5" />
                    1-844-YO-PELEO
                  </a>
                  <p className="mt-4 text-xs text-gray-500 dark:text-gray-500">
                    {language === 'es'
                      ? 'Disponible 24/7 para emergencias'
                      : 'Available 24/7 for emergencies'}
                  </p>
                </div>
              )}
            </div>
          </motion.div>
        )}
      </AnimatePresence>
    </>
  );
};

// Helper function for error messages
function getErrorMessage(error: string, language: 'en' | 'es'): string {
  const messages: Record<string, { en: string; es: string }> = {
    'network': {
      en: 'Network error. Please check your connection.',
      es: 'Error de red. Por favor verifica tu conexión.',
    },
    'no-speech': {
      en: 'No speech detected. Please try again.',
      es: 'No se detectó voz. Por favor intenta de nuevo.',
    },
    'audio-capture': {
      en: 'Microphone access denied. Please enable microphone permissions.',
      es: 'Acceso al micrófono denegado. Por favor habilita los permisos del micrófono.',
    },
    'not-allowed': {
      en: 'Microphone access not allowed. Please check your browser settings.',
      es: 'Acceso al micrófono no permitido. Por favor verifica la configuración de tu navegador.',
    },
  };

  return messages[error]?.[language] || 
    (language === 'es' ? 'Error desconocido. Por favor intenta de nuevo.' : 'Unknown error. Please try again.');
}

// Voice Assistant component for backward compatibility
export const VoiceAssistant = VirtualAssistant;

// Default export
export default VirtualAssistant;